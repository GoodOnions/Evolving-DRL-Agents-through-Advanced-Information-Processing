# Evolving Deep Reinforcement Learning Agents through Advanced Information Processing Strategies: U-Net Layers & Frame Merging

**Keywords:** `Deep Reinforcement Learning`, `Deep Q-Learning`, `Deep Convolutional Neural Networks`, `U-Net`, `Frame Merging`, `Information Processing`, `Computer Vision`, `OpenAI Gym`, `Keras`, `Python`
<p align="center">
    <img src="https://raw.githubusercontent.com/GoodOnions/ID2223-Lab1/main/imgs/goodonions_cover.png" alt="GoodOnions Official Repository"/>
</p>

## Team

**Name:** GoodOnions\
**Components:** [Daniele Cipollone](https://github.com/dancip00), [Federico Bono](https://github.com/FredBonux)

## Index
- [Presentation](https://pitch.com/v/II2202---Research-Project-eu26e9)
- [Report]()

<img src="https://raw.githubusercontent.com/vpulab/Semantic-Segmentation-Boost-Reinforcement-Learning/13a73318feeba91583fedd16ee6983118c79784e/Images/Mario_example.gif" width="600">

## Abstract
This research explores the impact of input preprocessing techniques on the learning efficiency
of Reinforcement Learning (RL) agents.

The study focuses on the integration of advanced image
processing and dimensionality reduction strategies to improve the performance of RL algorithms. Using
the OpenAI Gym framework and the Super Mario video game environment, the effectiveness of diverse
input preprocessing methods is examined. Key techniques investigated include semantic segmentation
and the use of autoencoders.

The research notably delves into the application of DeepLabV3 and U-
Net models for semantic segmentation, as well as the development of an N-Frame merging technique
for input data representation. Double Deep Q-Learning is employed to evaluate the effectiveness of
these preprocessing methods.

The results from various experiments, though not conclusively favoring
any single technique, provide valuable insights into the potential of preprocessing in enhancing RL
efficiency.


